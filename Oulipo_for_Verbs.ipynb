{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqBkuU/ybHgeo1EjoXT8UG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaizengrowth/machine_learning_projects/blob/main/Oulipo_for_Verbs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "dDRK9qmmgVvr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('dictionary.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Convert JSON data to pandas DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "types = df['pos'].unique()\n",
        "print(types)\n",
        "\n",
        "# Filter for verbs\n",
        "verbs_df = df[df['pos'] == 'v.']\n",
        "\n",
        "# Reset the index of verbs_df\n",
        "verbs_df = verbs_df.reset_index(drop=True)\n",
        "\n",
        "# # Display the DataFrame with verbs\n",
        "verbs_df.head()"
      ],
      "metadata": {
        "id": "o-AnE0aygecW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "b660b11e-0ec0-42b7-90c1-a79b033199d4"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['n.' 'prep.' 'a.' 'v.' 'adv.' 'p.' 'interj.' 'conj.' 'pron.']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  pos        word                                        definitions  \\\n",
              "0  v.   ABACINATE  [To blind by a red-hot metal plate held before...   \n",
              "1  v.  ABALIENATE  [To transfer the title of from one to another;...   \n",
              "2  v.       ABAND  [To abandon. [Obs.] Enforced the kingdom to ab...   \n",
              "3  v.     ABANDON  [To cast or drive out; to banish; to expel; to...   \n",
              "4  v.       ABASE  [To lower or depress; to throw or cast down; a...   \n",
              "\n",
              "                                            synonyms  \n",
              "0                                                NaN  \n",
              "1                                                NaN  \n",
              "2                                                NaN  \n",
              "3  give up; yield; forego; cede; surrender; resig...  \n",
              "4  Abase, Debase, Degrade. These words agree in t...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-444a0224-5b79-4c55-967f-423a8598800c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pos</th>\n",
              "      <th>word</th>\n",
              "      <th>definitions</th>\n",
              "      <th>synonyms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>v.</td>\n",
              "      <td>ABACINATE</td>\n",
              "      <td>[To blind by a red-hot metal plate held before...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>v.</td>\n",
              "      <td>ABALIENATE</td>\n",
              "      <td>[To transfer the title of from one to another;...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>v.</td>\n",
              "      <td>ABAND</td>\n",
              "      <td>[To abandon. [Obs.] Enforced the kingdom to ab...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v.</td>\n",
              "      <td>ABANDON</td>\n",
              "      <td>[To cast or drive out; to banish; to expel; to...</td>\n",
              "      <td>give up; yield; forego; cede; surrender; resig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>v.</td>\n",
              "      <td>ABASE</td>\n",
              "      <td>[To lower or depress; to throw or cast down; a...</td>\n",
              "      <td>Abase, Debase, Degrade. These words agree in t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-444a0224-5b79-4c55-967f-423a8598800c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-444a0224-5b79-4c55-967f-423a8598800c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-444a0224-5b79-4c55-967f-423a8598800c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5ff343a6-80ab-46d1-a906-b3636529c4a8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5ff343a6-80ab-46d1-a906-b3636529c4a8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5ff343a6-80ab-46d1-a906-b3636529c4a8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "verbs_df",
              "summary": "{\n  \"name\": \"verbs_df\",\n  \"rows\": 15872,\n  \"fields\": [\n    {\n      \"column\": \"pos\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"v.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12519,\n        \"samples\": [\n          \"WRIG\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"definitions\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"synonyms\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 923,\n        \"samples\": [\n          \"suggest; prescribe; enjoin; command; point out; urge; admonish.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "9ApsULasTA4J"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "wet folds\n",
        "\n",
        "while marvelling at an autocorrect algorithm that replaces the word\n",
        "\"fetish\" with the phrase \"fetus god\", i find a man staring into the\n",
        "fogged window of a golden krust shaving a patch of red hair from\n",
        "his upper lip while patrons, staring back, eat yellow pockets of\n",
        "shredded meats wrapped in a beige blanket of coco bread.\n",
        "\n",
        "a sign at the butcher next door reads:\n",
        "smoked pork\n",
        "neckbones,\n",
        "tails, and\n",
        "hocks\n",
        "\n",
        "halfway home, now.\n",
        "\n",
        "i consider the last time i found you. when the cancer hollowed your\n",
        "body and made your insides fleshy tunnels for radiation.            i found you.\n",
        "\n",
        "after three chunks of congealed blood emptied from my uterus onto\n",
        "a cotton pad, eight months following when i first met a man twice\n",
        "my senior, a week before i started 9th grade, and three days after i\n",
        "birthed a daughter, only, on mom’s velvet couch, which at the\n",
        "time, was covered in plastic. only, born with a full bottom row of\n",
        "teeth, drew blood during each feeding.\n",
        "\n",
        "i found you shortly\n",
        "after all of that.\n",
        "that, being only.\n",
        "\n",
        "i found you on the corner of fulton and nostrand underneath a tent\n",
        "of soiled newspapers: a bag of assorted pills in your right pocket, a\n",
        "dictionary of japanese words in the left. you were wearing one red\n",
        "sock and said you just landed on earth, but the others were coming.\n",
        "coming here. you mumbled auntie martine's name as two large\n",
        "men placed your body on a tattered stretcher and shoved your\n",
        "saggy flesh into the back of an ambulance next to another black\n",
        "body lying in a pool of cloudy liquid leaking from a ruptured\n",
        "colostomy bag.\n",
        "\n",
        "i\n",
        "\n",
        "rode in the front of the truck wedged between the two large men. i\n",
        "fished a half-eaten hard boiled egg from the bottom on my\n",
        "backpack covered in crumbs and lint that clung desperately to a\n",
        "greening yolk.\n",
        "\n",
        "later, you\n",
        "disappeared\n",
        "behind hospital\n",
        "curtains for several\n",
        "hours.\n",
        "\n",
        "a strangled blue. while you were lying in the hospital bed\n",
        "\n",
        "with one lung and a slack jaw, i was eating the jars of pickled pork\n",
        "left over from the gift basket aunt martine dropped off. when the\n",
        "pork finished, i began counting the ceiling tiles (there were\n",
        "ninety-six total).\n",
        "\n",
        "your left eye was swollen and covered with a crust, like the\n",
        "cornmeal batter you used to deep fry fish on friday nights back\n",
        "when we lived in that small house in stockton that was down the\n",
        "street from the church you refused to go to. (but, you’d go there on\n",
        "saturday mornings to get free boxes of canned beans and canned\n",
        "chicken packed in water, not oil) the other eye was full and alert,\n",
        "flickering without commitment.\n",
        "\n",
        "i watched a nurse fish irregularly sized chunks of pineapple from\n",
        "your mouth with her bare fingers as you choked and i slept at the\n",
        "foot of your bed. when your shallow breaths ceased two days later,\n",
        "i fit my head into your moist armpit like a tetris block and waited\n",
        "for the nurse to collect your body.\n",
        "\n",
        "death, unlike the\n",
        "nurse, was\n",
        "punctual.\n",
        "\n",
        "you are the third person to die this year in a dank hospital with\n",
        "quiet nurses. between the wet folds of your skin, i left notes written\n",
        "on magenta construction paper. on them, i wrote questions for god.\n",
        "when i talk to god, he does not respond so i send notes with the\n",
        "dead, like you, in the hope that when you meet him, you can\n",
        "acquire some answers for me.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "y3MgeuBHV3Q3"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Process the text with SpaCy\n",
        "import string\n",
        "\n",
        "# Initialize a dictionary to store verbs and their indices\n",
        "verb_indices = {}\n",
        "\n",
        "# Remove punctuation from the text\n",
        "text_without_punctuation = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "# Split the text into words\n",
        "words = text_without_punctuation.split()\n",
        "\n",
        "# Initialize a dictionary to store verbs and their indices\n",
        "verb_indices = {}\n",
        "\n",
        "# Iterate through each word in the text\n",
        "for index, word in enumerate(words):\n",
        "    # Process the word with SpaCy\n",
        "    doc = nlp(word)\n",
        "    # Check if the processed word is a verb\n",
        "    if doc[0].pos_ == 'VERB':\n",
        "        # Store the verb and its index in the dictionary\n",
        "        verb_indices[index] = word\n",
        "\n",
        "# Print the verbs and their indices\n",
        "print(\"Verbs and Indices:\", verb_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zesJF7IsUJNm",
        "outputId": "1f85b1b6-e6f3-4296-fc05-bd23fd4a7a10"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verbs and Indices: {1: 'folds', 3: 'marvelling', 9: 'replaces', 19: 'find', 22: 'staring', 25: 'fogged', 33: 'patch', 43: 'staring', 45: 'eat', 49: 'shredded', 51: 'wrapped', 54: 'beige', 55: 'blanket', 60: 'sign', 63: 'butcher', 66: 'reads', 67: 'smoked', 77: 'consider', 82: 'found', 87: 'hollowed', 91: 'made', 93: 'insides', 99: 'found', 103: 'chunks', 105: 'congealed', 107: 'emptied', 117: 'following', 121: 'met', 131: 'started', 139: 'birthed', 152: 'covered', 156: 'born', 161: 'row', 164: 'drew', 168: 'feeding', 170: 'found', 181: 'found', 194: 'soiled', 199: 'assorted', 212: 'left', 215: 'wearing', 220: 'said', 223: 'landed', 230: 'coming', 231: 'coming', 234: 'mumbled', 242: 'placed', 247: 'tattered', 250: 'shoved', 265: 'lying', 272: 'leaking', 275: 'ruptured', 279: 'rode', 286: 'wedged', 293: 'fished', 295: 'halfeaten', 297: 'boiled', 305: 'covered', 309: 'lint', 315: 'greening', 316: 'yolk', 319: 'disappeared', 322: 'curtains', 327: 'strangled', 332: 'lying', 346: 'eating', 350: 'pickled', 352: 'left', 360: 'dropped', 365: 'finished', 367: 'began', 368: 'counting', 377: 'left', 380: 'swollen', 382: 'covered', 389: 'batter', 391: 'used', 394: 'fry', 402: 'lived', 418: 'refused', 420: 'go', 424: 'go', 430: 'get', 434: 'canned', 437: 'canned', 439: 'packed', 451: 'flickering', 455: 'watched', 460: 'sized', 461: 'chunks', 473: 'choked', 476: 'slept', 485: 'shallow', 487: 'ceased', 502: 'block', 504: 'waited', 509: 'collect', 524: 'die', 533: 'nurses', 537: 'folds', 542: 'left', 543: 'notes', 544: 'written', 552: 'wrote', 558: 'talk', 562: 'does', 564: 'respond', 567: 'send', 568: 'notes', 580: 'meet', 584: 'acquire'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_verbs = {}\n",
        "for verb in verb_indices.values():\n",
        "    # Process the verb with SpaCy\n",
        "    doc = nlp(verb)\n",
        "    # Get the lemma of the verb\n",
        "    lemmatized_verb = doc[0].lemma_\n",
        "    # Append the lemmatized verb to the list\n",
        "    lemmatized_verbs[verb] = lemmatized_verb.upper()\n",
        "\n",
        "print(lemmatized_verbs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66v-uo4yXEXN",
        "outputId": "febd714e-0ffd-4ff6-d77c-c266190964a7"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'folds': 'FOLD', 'marvelling': 'MARVEL', 'replaces': 'REPLACE', 'find': 'FIND', 'staring': 'STARE', 'fogged': 'FOG', 'patch': 'PATCH', 'eat': 'EAT', 'shredded': 'SHRED', 'wrapped': 'WRAP', 'beige': 'BEIGE', 'blanket': 'BLANKET', 'sign': 'SIGN', 'butcher': 'BUTCHER', 'reads': 'READ', 'smoked': 'SMOKE', 'consider': 'CONSIDER', 'found': 'FIND', 'hollowed': 'HOLLOW', 'made': 'MAKE', 'insides': 'INSIDE', 'chunks': 'CHUNK', 'congealed': 'CONGEAL', 'emptied': 'EMPTY', 'following': 'FOLLOW', 'met': 'MEET', 'started': 'START', 'birthed': 'BIRTH', 'covered': 'COVER', 'born': 'BEAR', 'row': 'ROW', 'drew': 'DRAW', 'feeding': 'FEED', 'soiled': 'SOIL', 'assorted': 'ASSORT', 'left': 'LEAVE', 'wearing': 'WEAR', 'said': 'SAY', 'landed': 'LAND', 'coming': 'COME', 'mumbled': 'MUMBLE', 'placed': 'PLACE', 'tattered': 'TATTERE', 'shoved': 'SHOVE', 'lying': 'LIE', 'leaking': 'LEAK', 'ruptured': 'RUPTURE', 'rode': 'RIDE', 'wedged': 'WEDGE', 'fished': 'FISH', 'halfeaten': 'HALFEATEN', 'boiled': 'BOIL', 'lint': 'LINT', 'greening': 'GREEN', 'yolk': 'YOLK', 'disappeared': 'DISAPPEAR', 'curtains': 'CURTAIN', 'strangled': 'STRANGLE', 'eating': 'EAT', 'pickled': 'PICKLE', 'dropped': 'DROP', 'finished': 'FINISH', 'began': 'BEGIN', 'counting': 'COUNT', 'swollen': 'SWOLLEN', 'batter': 'BATTER', 'used': 'USE', 'fry': 'FRY', 'lived': 'LIVE', 'refused': 'REFUSE', 'go': 'GO', 'get': 'GET', 'canned': 'CAN', 'packed': 'PACK', 'flickering': 'FLICKER', 'watched': 'WATCH', 'sized': 'SIZE', 'choked': 'CHOKE', 'slept': 'SLEEP', 'shallow': 'SHALLOW', 'ceased': 'CEASE', 'block': 'BLOCK', 'waited': 'WAIT', 'collect': 'COLLECT', 'die': 'DIE', 'nurses': 'NURSE', 'notes': 'NOTE', 'written': 'WRITE', 'wrote': 'WRITE', 'talk': 'TALK', 'does': 'DO', 'respond': 'RESPOND', 'send': 'SEND', 'meet': 'MEET', 'acquire': 'ACQUIRE'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a dictionary to store locations of lemmatized verbs\n",
        "lemmatized_verb_locations = {}\n",
        "\n",
        "# Iterate through each lemmatized word\n",
        "for verb, lemmatized_verb in lemmatized_verbs.items():\n",
        "    # Find the index of the lemmatized word in the verbs_df DataFrame\n",
        "    indices = verbs_df.index[verbs_df['word'] == lemmatized_verb].tolist()\n",
        "\n",
        "    # Store the first location of the lemmatized verb in the DataFrame\n",
        "    if indices:\n",
        "        first_index = indices[0]  # Take the first index\n",
        "        lemmatized_verb_locations[lemmatized_verb] = first_index\n",
        "\n",
        "# Print the locations of lemmatized verbs\n",
        "print(\"Lemmatized Verb Locations:\", lemmatized_verb_locations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiVKeL3hefft",
        "outputId": "0d3aa935-adb2-4b2b-a0b9-49220a4449ed"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatized Verb Locations: {'FOLD': 5646, 'MARVEL': 8316, 'REPLACE': 11580, 'FIND': 5477, 'STARE': 13270, 'FOG': 5637, 'PATCH': 9851, 'EAT': 4390, 'SHRED': 12542, 'WRAP': 15775, 'BLANKET': 1333, 'SIGN': 12601, 'BUTCHER': 1703, 'READ': 11007, 'SMOKE': 12832, 'CONSIDER': 2584, 'HOLLOW': 6682, 'MAKE': 8240, 'CONGEAL': 2533, 'EMPTY': 4632, 'FOLLOW': 5653, 'MEET': 8393, 'START': 13273, 'COVER': 2820, 'BEAR': 947, 'ROW': 11993, 'DRAW': 4260, 'FEED': 5391, 'SOIL': 12936, 'ASSORT': 657, 'LEAVE': 7954, 'WEAR': 15531, 'SAY': 12138, 'LAND': 7867, 'COME': 2357, 'MUMBLE': 8902, 'PLACE': 10140, 'SHOVE': 12533, 'LIE': 8031, 'LEAK': 7941, 'RUPTURE': 12038, 'RIDE': 11851, 'WEDGE': 15547, 'FISH': 5498, 'BOIL': 1429, 'GREEN': 6303, 'DISAPPEAR': 3688, 'CURTAIN': 3007, 'STRANGLE': 13413, 'PICKLE': 10067, 'DROP': 4309, 'FINISH': 5491, 'BEGIN': 1025, 'COUNT': 2765, 'BATTER': 926, 'USE': 15221, 'FRY': 5930, 'LIVE': 8106, 'REFUSE': 11332, 'GO': 6225, 'GET': 6111, 'CAN': 1779, 'PACK': 9717, 'FLICKER': 5568, 'WATCH': 15502, 'SIZE': 12660, 'CHOKE': 2063, 'SLEEP': 12745, 'SHALLOW': 12428, 'CEASE': 1910, 'BLOCK': 1379, 'WAIT': 15434, 'COLLECT': 2331, 'DIE': 3589, 'NURSE': 9084, 'NOTE': 9056, 'WRITE': 15801, 'TALK': 13859, 'DO': 4175, 'RESPOND': 11695, 'SEND': 12359, 'ACQUIRE': 137}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_verbs_list = {}\n",
        "\n",
        "# Iterate through each verb and its locations\n",
        "for verb, location in lemmatized_verb_locations.items():\n",
        "    if location is not None:\n",
        "      new_index = location + 7\n",
        "\n",
        "      try:\n",
        "          # Try to access the verb at the calculated index\n",
        "          new_verb = verbs_df.loc[new_index, 'word']\n",
        "\n",
        "          # Store the new location and replacement in the new_verbs_list dictionary\n",
        "          if verb not in new_verbs_list:\n",
        "              new_verbs_list[verb] = new_verb\n",
        "          else:\n",
        "              new_verbs_list[verb].append(new_verb)\n",
        "\n",
        "      except KeyError:\n",
        "          # If the index is beyond the range of the DataFrame, skip this word\n",
        "          print(f\"Index {new_index} is beyond the range of the DataFrame. Skipping...\")\n",
        "          continue\n",
        "\n",
        "# Print the new_verbs_list dictionary\n",
        "print(\"New Verbs:\", new_verbs_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDuEqG5XeFzw",
        "outputId": "8445d6c1-e0db-410e-87da-324feb91ab74"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Verbs: {'FOLD': 'FOLLOW', 'MARVEL': 'MASON', 'REPLACE': 'REPLEVIN', 'FIND': 'FINEER', 'STARE': 'STARVE', 'FOG': 'FOIN', 'PATCH': 'PATROL', 'EAT': 'ECCHYMOSE', 'SHRED': 'SHRIMP', 'WRAP': 'WREAK', 'BLANKET': 'BLAST', 'SIGN': 'SIGNIORIZE', 'BUTCHER': 'BUTTRESS', 'READ': 'READOPT', 'SMOKE': 'SMOOTH', 'CONSIDER': 'CONSOCIATE', 'HOLLOW': 'HONE', 'MAKE': 'MALIGN', 'CONGEAL': 'CONGLOBE', 'EMPTY': 'EMULE', 'FOLLOW': 'FONDLE', 'MEET': 'MELIORATE', 'START': 'STATION', 'COVER': 'COWARDIZE', 'BEAR': 'BEATIFICATE', 'ROW': 'RUB', 'DRAW': 'DREAM', 'FEED': 'FEINT', 'SOIL': 'SOLARIZE', 'ASSORT': 'ASSUME', 'LEAVE': 'LECTURE', 'WEAR': 'WEATHERBIT', 'SAY': 'SCALD', 'LAND': 'LANIATE', 'COME': 'COMMANDEER', 'MUMBLE': 'MUNCH', 'PLACE': 'PLAIN', 'SHOVE': 'SHRAG', 'LIE': 'LIGATURE', 'LEAK': 'LEARN', 'RUPTURE': 'RUSSIFY', 'RIDE': 'RIFLE', 'WEDGE': 'WEIGH', 'FISH': 'FIT', 'BOIL': 'BOLN', 'GREEN': 'GREITH', 'DISAPPEAR': 'DISARRAY', 'CURTAIN': 'CUSPIDATE', 'STRANGLE': 'STRAW', 'PICKLE': 'PIECE', 'DROP': 'DRUB', 'FINISH': 'FISH', 'BEGIN': 'BEGORE', 'COUNT': 'COUNTERBRACE', 'BATTER': 'BAWL', 'USE': 'UTTER', 'FRY': 'FUFF', 'LIVE': 'LOAM', 'REFUSE': 'REGARD', 'GO': 'GOD', 'GET': 'GIB', 'CAN': 'CANDY', 'PACK': 'PADDLE', 'FLICKER': 'FLIRT', 'WATCH': 'WATER-ROT', 'SIZE': 'SKELDER', 'CHOKE': 'CHOP', 'SLEEP': 'SLICE', 'SHALLOW': 'SHAMPOO', 'CEASE': 'CELL', 'BLOCK': 'BLOSSOM', 'WAIT': 'WAKEN', 'COLLECT': 'COLLOCATE', 'DIE': 'DIFFERENTIATE', 'NURSE': 'OAR', 'NOTE': 'NOURISH', 'WRITE': 'WROTE', 'TALK': 'TAME', 'DO': 'DOCTOR', 'RESPOND': 'RESTATE', 'SEND': 'SENSUALIZE', 'ACQUIRE': 'ACTIVATE'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_verbs = {}\n",
        "\n",
        "for verb in lemmatized_verbs:\n",
        "    try:\n",
        "        # Check if the lemmatized form of the verb exists in new_verbs_list\n",
        "        new_verb = new_verbs_list[lemmatized_verbs[verb]]\n",
        "        # If it exists, store it in new_verbs dictionary\n",
        "        new_verbs[verb] = new_verb\n",
        "    except KeyError:\n",
        "        continue\n",
        "\n",
        "print(new_verbs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbY1ImvdpEk4",
        "outputId": "749479b2-444b-4789-f042-998812834602"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'folds': 'FOLLOW', 'marvelling': 'MASON', 'replaces': 'REPLEVIN', 'find': 'FINEER', 'staring': 'STARVE', 'fogged': 'FOIN', 'patch': 'PATROL', 'eat': 'ECCHYMOSE', 'shredded': 'SHRIMP', 'wrapped': 'WREAK', 'blanket': 'BLAST', 'sign': 'SIGNIORIZE', 'butcher': 'BUTTRESS', 'reads': 'READOPT', 'smoked': 'SMOOTH', 'consider': 'CONSOCIATE', 'found': 'FINEER', 'hollowed': 'HONE', 'made': 'MALIGN', 'congealed': 'CONGLOBE', 'emptied': 'EMULE', 'following': 'FONDLE', 'met': 'MELIORATE', 'started': 'STATION', 'covered': 'COWARDIZE', 'born': 'BEATIFICATE', 'row': 'RUB', 'drew': 'DREAM', 'feeding': 'FEINT', 'soiled': 'SOLARIZE', 'assorted': 'ASSUME', 'left': 'LECTURE', 'wearing': 'WEATHERBIT', 'said': 'SCALD', 'landed': 'LANIATE', 'coming': 'COMMANDEER', 'mumbled': 'MUNCH', 'placed': 'PLAIN', 'shoved': 'SHRAG', 'lying': 'LIGATURE', 'leaking': 'LEARN', 'ruptured': 'RUSSIFY', 'rode': 'RIFLE', 'wedged': 'WEIGH', 'fished': 'FIT', 'boiled': 'BOLN', 'greening': 'GREITH', 'disappeared': 'DISARRAY', 'curtains': 'CUSPIDATE', 'strangled': 'STRAW', 'eating': 'ECCHYMOSE', 'pickled': 'PIECE', 'dropped': 'DRUB', 'finished': 'FISH', 'began': 'BEGORE', 'counting': 'COUNTERBRACE', 'batter': 'BAWL', 'used': 'UTTER', 'fry': 'FUFF', 'lived': 'LOAM', 'refused': 'REGARD', 'go': 'GOD', 'get': 'GIB', 'canned': 'CANDY', 'packed': 'PADDLE', 'flickering': 'FLIRT', 'watched': 'WATER-ROT', 'sized': 'SKELDER', 'choked': 'CHOP', 'slept': 'SLICE', 'shallow': 'SHAMPOO', 'ceased': 'CELL', 'block': 'BLOSSOM', 'waited': 'WAKEN', 'collect': 'COLLOCATE', 'die': 'DIFFERENTIATE', 'nurses': 'OAR', 'notes': 'NOURISH', 'written': 'WROTE', 'wrote': 'WROTE', 'talk': 'TAME', 'does': 'DOCTOR', 'respond': 'RESTATE', 'send': 'SENSUALIZE', 'meet': 'MELIORATE', 'acquire': 'ACTIVATE'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "new_text = text\n",
        "\n",
        "# Define a regular expression pattern to match whole words\n",
        "pattern = r'\\b(?:{})\\b'.format('|'.join(re.escape(word) for word in new_verbs.keys()))\n",
        "\n",
        "# Use re.sub to perform the replacements while respecting word boundaries\n",
        "new_text = re.sub(pattern, lambda match: new_verbs.get(match.group(0), match.group(0)), new_text)\n",
        "\n",
        "print(new_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxEQsnzZsitB",
        "outputId": "cf5ce4f6-f1b8-4214-b265-eb7d820ced2e"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "wet FOLLOW\n",
            "\n",
            "while MASON at an autocorrect algorithm that REPLEVIN the word\n",
            "\"fetish\" with the phrase \"fetus god\", i FINEER a man STARVE into the\n",
            "FOIN window of a golden krust shaving a PATROL of red hair from\n",
            "his upper lip while patrons, STARVE back, ECCHYMOSE yellow pockets of\n",
            "SHRIMP meats WREAK in a beige BLAST of coco bread.\n",
            "\n",
            "a SIGNIORIZE at the BUTTRESS next door READOPT:\n",
            "SMOOTH pork\n",
            "neckbones,\n",
            "tails, and\n",
            "hocks\n",
            "\n",
            "halfway home, now.\n",
            "\n",
            "i CONSOCIATE the last time i FINEER you. when the cancer HONE your\n",
            "body and MALIGN your insides fleshy tunnels for radiation.            i FINEER you.\n",
            "\n",
            "after three chunks of CONGLOBE blood EMULE from my uterus onto\n",
            "a cotton pad, eight months FONDLE when i first MELIORATE a man twice\n",
            "my senior, a week before i STATION 9th grade, and three days after i\n",
            "birthed a daughter, only, on mom’s velvet couch, which at the\n",
            "time, was COWARDIZE in plastic. only, BEATIFICATE with a full bottom RUB of\n",
            "teeth, DREAM blood during each FEINT.\n",
            "\n",
            "i FINEER you shortly\n",
            "after all of that.\n",
            "that, being only.\n",
            "\n",
            "i FINEER you on the corner of fulton and nostrand underneath a tent\n",
            "of SOLARIZE newspapers: a bag of ASSUME pills in your right pocket, a\n",
            "dictionary of japanese words in the LECTURE. you were WEATHERBIT one red\n",
            "sock and SCALD you just LANIATE on earth, but the others were COMMANDEER.\n",
            "COMMANDEER here. you MUNCH auntie martine's name as two large\n",
            "men PLAIN your body on a tattered stretcher and SHRAG your\n",
            "saggy flesh into the back of an ambulance next to another black\n",
            "body LIGATURE in a pool of cloudy liquid LEARN from a RUSSIFY\n",
            "colostomy bag.\n",
            "\n",
            "i\n",
            "\n",
            "RIFLE in the front of the truck WEIGH between the two large men. i\n",
            "FIT a half-eaten hard BOLN egg from the bottom on my\n",
            "backpack COWARDIZE in crumbs and lint that clung desperately to a\n",
            "GREITH yolk.\n",
            "\n",
            "later, you\n",
            "DISARRAY\n",
            "behind hospital\n",
            "CUSPIDATE for several\n",
            "hours.\n",
            "\n",
            "a STRAW blue. while you were LIGATURE in the hospital bed\n",
            "\n",
            "with one lung and a slack jaw, i was ECCHYMOSE the jars of PIECE pork\n",
            "LECTURE over from the gift basket aunt martine DRUB off. when the\n",
            "pork FISH, i BEGORE COUNTERBRACE the ceiling tiles (there were\n",
            "ninety-six total).\n",
            "\n",
            "your LECTURE eye was swollen and COWARDIZE with a crust, like the\n",
            "cornmeal BAWL you UTTER to deep FUFF fish on friday nights back\n",
            "when we LOAM in that small house in stockton that was down the\n",
            "street from the church you REGARD to GOD to. (but, you’d GOD there on\n",
            "saturday mornings to GIB free boxes of CANDY beans and CANDY\n",
            "chicken PADDLE in water, not oil) the other eye was full and alert,\n",
            "FLIRT without commitment.\n",
            "\n",
            "i WATER-ROT a nurse fish irregularly SKELDER chunks of pineapple from\n",
            "your mouth with her bare fingers as you CHOP and i SLICE at the\n",
            "foot of your bed. when your SHAMPOO breaths CELL two days later,\n",
            "i fit my head into your moist armpit like a tetris BLOSSOM and WAKEN\n",
            "for the nurse to COLLOCATE your body.\n",
            "\n",
            "death, unlike the\n",
            "nurse, was\n",
            "punctual.\n",
            "\n",
            "you are the third person to DIFFERENTIATE this year in a dank hospital with\n",
            "quiet OAR. between the wet FOLLOW of your skin, i LECTURE NOURISH WROTE\n",
            "on magenta construction paper. on them, i WROTE questions for god.\n",
            "when i TAME to god, he DOCTOR not RESTATE so i SENSUALIZE NOURISH with the\n",
            "dead, like you, in the hope that when you MELIORATE him, you can\n",
            "ACTIVATE some answers for me.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0bGM_mdGjZoC"
      },
      "execution_count": 98,
      "outputs": []
    }
  ]
}